<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Estimation of the multilevel hidden Markov model</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>






<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Estimation of the multilevel hidden Markov
model</h1>
<h4 class="author">Emmeke Aarts</h4>
<address class="author_afil">
Department of Methodology and Statistics, Utrecht University, Utrecht,
the Netherlands <br><br>


<p>There are several methods to estimate the parameters of a hidden
Markov model (HMM). To be complete, we discuss three methods typically
used when assumed that the data is generated by one (uni-level) model.
That is, the Maximum Likelihood approach, the Baum Welch algorithm
utilizing the forward backward probabilities, and the Bayesian
estimation method. Note that all these methods assume that the number of
states is known from the context of the application, i.e., specified by
the user. The issue of determining the number of states is discussed in
the vignette “tutorial-mhmm”.</p>
<p>After discussing the simplified case of estimating the parameters
where the data consists of only one observed sequence (or, with multiple
sequences, assuming that all data is generated by one identical model),
we proceed with elaborating on estimating the parameters of a multilevel
hidden Markov model.</p>
<div id="estimating-the-parameters-of-the-hmm" class="section level1">
<h1>Estimating the parameters of the HMM</h1>
<div id="maximum-likelihood-ml" class="section level2">
<h2>Maximum likelihood (ML)</h2>
<p>ML estimation can be used to estimate the parameters of the HMM. The
relevant likelihood function has a convenient form: <span class="math display">\[\begin{equation}
L_T = \mathbf{\delta P}(o_1) \mathbf{\Gamma P}(o_2)\mathbf{\Gamma
P}(o_3) \ldots \mathbf{\Gamma P}(o_T) \mathbf{1&#39;}.
\end{equation}\]</span> Here, <span class="math inline">\(\mathbf{P}(o_t)\)</span> denotes a diagonal matrix
with the state-dependent conditional probabilities of observing <span class="math inline">\(O_t = o\)</span> as entries, <span class="math inline">\(\mathbf{\delta}\)</span> denotes the distribution
of the initial probabilities <span class="math inline">\(\pi_i\)</span>,
<span class="math inline">\(\mathbf{\Gamma}\)</span> denotes the
transition probability matrix, and <span class="math inline">\(\mathbf{1&#39;}\)</span> is a column vector
consisting of <span class="math inline">\(m\)</span> (i.e., the number
of distinct states) elements which all have the value one. See the
vignette “tutorial-mhmm” for an explanation of these quantities. Direct
maximization of the log-likelihood poses no problems even for very long
sequences, provided measures are taken to avoid numerical underflow.</p>
</div>
<div id="expectation-maximization-em-or-baum-welch-algorithm" class="section level2">
<h2>Expectation Maximization (EM) or Baum-Welch algorithm</h2>
<p>The EM algorithm <span class="citation">(Dempster, Laird, and Rubin
1977)</span>, in this context also known as the Baum-Welch algorithm
<span class="citation">(Baum et al. 1970; Rabiner 1989)</span>, can also
be used to maximize the log-likelihood function. Here, the unobserved
latent states are treated as missing data, and quantities known as the
forward and the backward probabilities are used to obtain the
‘complete-data log-likelihood’ of the HMM parameters: the log-likelihood
based on both the observed event sequence and the unobserved, or
“missing”, latent states. The forward probabilities <span class="math inline">\(\boldsymbol{\alpha}_t (i)\)</span> denote the
joint probability of the observed event sequence from time point 1 to
<span class="math inline">\(t\)</span> and state <span class="math inline">\(S\)</span> at time point <span class="math inline">\(t\)</span> being <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\label{forward}
\boldsymbol{\alpha}_t (i) = Pr(O_1 = o_1, O_2 = o_2, \ldots, O_t = o_t,
S_t = i).
\end{equation}\]</span></p>
<p>The name “forward probabilities” derives from the fact that when
computing the forward probabilities <span class="math inline">\(\boldsymbol{\alpha}_t\)</span>, one evaluates the
sequence of hidden states in the chronological order (i.e., forward in
time) until time point <span class="math inline">\(t\)</span>. The
backward probabilities <span class="math inline">\(\boldsymbol{\beta}_t
(i)\)</span> denote the conditional probability of the observed event
sequence after time point <span class="math inline">\(t\)</span> until
the end, so from <span class="math inline">\(t+1, t+2, \ldots
,T\)</span>, given that state <span class="math inline">\(S\)</span> at
time point <span class="math inline">\(t\)</span> equals <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\beta}_t (i) = Pr(O_{t+1} = o_{t+1}, O_{t+2} = o_{t+2},
\ldots, O_T = o_T \mid S_t = i).
\end{equation}\]</span></p>
<p>When computing the backward probabilities <span class="math inline">\(\boldsymbol{\beta}_t\)</span>, one evaluates the
sequence of hidden states in the reversed order, i.e., from <span class="math inline">\(S_T, S_{T-1}, \ldots, S_{t+1}\)</span>. The
forward and backward probabilities together cover the complete event
sequence from <span class="math inline">\(t = 1\)</span> to <span class="math inline">\(T\)</span>, and combined give the joint
probability of the complete event sequence and state <span class="math inline">\(S\)</span> at time point <span class="math inline">\(t\)</span> being <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\alpha}_t (i)\boldsymbol{\beta}_t (i) = Pr(O_{1} = o_{1},
O_{2} = o_{2}, \ldots, O_T = o_T, S_t = i).
\end{equation}\]</span></p>
<p>We refer to <span class="citation">Cappé (2005)</span> for a
discussion on the advantages of combining forward and backward
probability information in the EM algorithm over direct maximization of
the likelihood for the HMM.</p>
</div>
<div id="bayesian-estimation" class="section level2">
<h2>Bayesian estimation</h2>
<p>A third approach is to use Bayesian estimation to infer the
parameters of the HMM. We refer to e.g., <span class="citation">Gelman
et al. (2014)</span>, <span class="citation">Lynch (2007)</span>, <span class="citation">Rossi, Allenby, and McCulloch (2012)</span> for an
in-depth exposition of Bayesian statistics. In general terms, the
difference between frequentist and Bayesian estimation is the following.
In frequentist estimation, we view the parameters as fixed entities in
the population, which are subject only to sampling fluctuation (as
quantified in the standard error of the estimate). In Bayesian
estimation, however, we assume that each parameter follows a given
distribution. The general shape of this distribution is determined
beforehand, using a prior distribution. This prior distribution not only
determines the shape of the parameter distribution, but also allows for
giving some information to the model with respect to the most likely
values of the parameter that is estimated. To arrive at the final
distribution for the parameter - which is called the posterior
distribution -, the prior distribution is combined with the likelihood
function of the data using Bayes’ theorem. Here, the likelihood function
provides us with the probability of the data given the parameters. While
any aspect of these distributions may be of interest, the emphasis is
usually on the mean (or median) of the posterior distribution, which
serves as the point estimate of the parameter of interest (analogous to
the frequentist parameter estimates). In the event that one has no or
vague expectations about the possible parameter values, one can specify
“non-informative” priors (e.g., uniform distribution). That is, one can
choose parameters of the prior distributions, so called
hyper-parameters, such that the parameters may assume a wide range of
possible values. Non-informative priors therefore express a lack of
knowledge.</p>
<p>In the implemented hidden Markov model, both the transitions from
state <span class="math inline">\(i\)</span> at time point <span class="math inline">\(t\)</span> to any of the other states at time
point <span class="math inline">\(t + 1\)</span> and the observed
outcomes within state <span class="math inline">\(i\)</span> follow a
categorical distribution, with parameter sets <span class="math inline">\(\mathbf{\Gamma}_i\)</span> (i.e., the
probabilities in row <span class="math inline">\(i\)</span> of the
transition probability matrix <span class="math inline">\(\mathbf{\Gamma}\)</span>) and <span class="math inline">\(\boldsymbol{\theta}_i\)</span> (i.e., the state
<span class="math inline">\(i\)</span> dependent probabilities of
observing an act). A convenient (conjugate) prior distribution on the
parameters of the categorical distribution is a (symmetric) Dirichlet
distribution. We assume that the rows of <span class="math inline">\(\mathbf{\Gamma}\)</span> and the state-dependent
probabilities <span class="math inline">\(\boldsymbol{\theta}_i\)</span>
are independent. That is,</p>
<p><span class="math display">\[\begin{align}
S_{t = 2, \ldots, T} \: \sim \mathbf{\Gamma}_{S_{t-1}} \quad
&amp;\text{with} \quad \mathbf{\Gamma}_i \: \sim
\text{Dir}(\mathbf{a}_{10}) \quad \text{and}
\label{gammaDirPrior}\\  O_{t = 1, \ldots, T} \:
\sim\boldsymbol{\theta}_{S_t} \quad &amp;\text{with} \quad
\boldsymbol{\theta}_i    \: \sim \text{Dir}(\mathbf{a}_{20}),
\label{pDirPrior}
\end{align}\]</span></p>
<p>where the probability distribution of the current state <span class="math inline">\(S_t\)</span> is given by the row of the transition
probability matrix <span class="math inline">\(\mathbf{\Gamma}\)</span>
corresponding to the previous state in the hidden state sequence <span class="math inline">\(S_{t-1}\)</span>. The probability distribution of
<span class="math inline">\(S_t\)</span> given by <span class="math inline">\(\mathbf{\Gamma}\)</span> holds for states after
the first time point, i.e., t starts at 2 as there is no previous state
in the hidden state sequence for state <span class="math inline">\(S\)</span> at <span class="math inline">\(t =
1\)</span>. The probability of the first state in the hidden state
sequence <span class="math inline">\(S_1\)</span> is given by the
initial probabilities of the states <span class="math inline">\(\pi_i\)</span>. The probability distribution of
the observed event <span class="math inline">\(O_t\)</span> is given by
state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_i\)</span> corresponding to
the current state <span class="math inline">\(S_t\)</span>. The
hyper-parameter <span class="math inline">\(\mathbf{a}_{10}\)</span> of
the prior Dirichlet distribution on <span class="math inline">\(\mathbf{\Gamma}_i\)</span> is a vector with length
equal to the number of states <span class="math inline">\(m\)</span>,
and the hyper-parameter <span class="math inline">\(\mathbf{a}_{20}\)</span> of the prior Dirichlet
distribution on <span class="math inline">\(\boldsymbol{\theta}_i\)</span> is a vector with
length equal to the number of categorical outcomes <span class="math inline">\(q\)</span>. Note that in this model, the
hyper-parameter values are assumed invariant over the states <span class="math inline">\(i\)</span>. The initial probabilities of the
states <span class="math inline">\(\pi_i\)</span> are assumed to
coincide with the stationary distribution of <span class="math inline">\(\boldsymbol{\Gamma}\)</span> and are therefore not
independent (to-be-estimated) parameters.</p>
<p>Given these distributions, our goal is to construct the joint
posterior distribution of the hidden state sequence and the parameter
estimates, given the observed event sequence and the hyper-parameters
<span class="math display">\[\begin{equation}
\Pr\big((S_t), \mathbf{\Gamma}_i ,  \boldsymbol{\theta}_i \mid
(O_t)\big)
\propto \Pr\big((O_t) \mid (S_t), \boldsymbol{\theta}_i  \big)
\Pr\big((S_t) \mid \mathbf{\Gamma}_i  \big)
\Pr\big(\mathbf{\Gamma}_i  \mid \mathbf{a}_{10} \big)
\Pr\big(\boldsymbol{\theta}_i \mid \mathbf{a}_{20} \big)
% \mathbf{a}_{10}, \mathbf{a}_{20}
\end{equation}\]</span> by drawing samples from the posterior
distribution. By applying a Gibbs sampler, we can iteratively sample
from the appropriate conditional posterior distributions of <span class="math inline">\(S_t\)</span>, <span class="math inline">\(\mathbf{\Gamma}_i\)</span> and <span class="math inline">\(\boldsymbol{\theta}_i\)</span>, given the
remaining parameters in the model. In short, the Gibbs sampler iterates
between the following two steps: first the hidden state sequence <span class="math inline">\(S_1, S_2, \ldots, S_T\)</span> is sampled, given,
the observed event sequence <span class="math inline">\(O_1, O_2,
\ldots, O_T\)</span>, and the current values of the parameters <span class="math inline">\(\mathbf{\Gamma}\)</span> and <span class="math inline">\(\boldsymbol{\theta}_i\)</span>. Subsequently, the
remaining parameters in the model (<span class="math inline">\(\mathbf{\Gamma}_i\)</span> and <span class="math inline">\(\boldsymbol{\theta}_i\)</span>) are updated by
sampling them conditional on the sampled hidden state sequence <span class="math inline">\(S_1, S_2, \ldots, S_T\)</span> and observed event
sequence <span class="math inline">\(O_1, O_2, \ldots, O_T\)</span>.</p>
<p>Sampling the hidden state sequence of the HMM by means of the Gibbs
sampler can be performed in various ways. Here, we use the approach
outlined by <span class="citation">Scott (2002)</span>. That is, we use
the forward-backward Gibbs sampler, in which first the forward
probabilities <span class="math inline">\(\boldsymbol{\alpha}_{t}(i)\)</span> (i.e., the
joint probability of state <span class="math inline">\(S = i\)</span> at
time point <span class="math inline">\(t\)</span> and the observed event
sequence from time point 1 to <span class="math inline">\(t\)</span>,
see above equation) are obtained, after which the hidden state sequence
is sampled in a backward run (i.e., drawing <span class="math inline">\(S_T, S_{T-1}, \ldots, S_1\)</span>) using the
corresponding forward probabilities <span class="math inline">\(\boldsymbol{\alpha}_{T:1}\)</span>. The
forward-backward Gibbs sampler produces sampled values that rapidly
represent the complete area of the posterior distribution, and produces
useful quantities as byproducts, such as the log-likelihood of the
observed data given the current draws of the parameters in each
iteration <span class="citation">(Scott 2002)</span>. In the section “”
, we provide a more detailed description of how the Gibbs sampler
proceeds for the HMM.</p>
<p>As it generally takes a number of iterations before the Gibbs sampler
converges to the appropriate region of the posterior distribution, the
initial iterations are usually discarded as a ‘burn-in’ period. The
remaining sampled values of <span class="math inline">\(\mathbf{\Gamma}_i\)</span> and <span class="math inline">\(\boldsymbol{\theta}_i\)</span> provide the
posterior distributions of their respective parameters.</p>
<p>A problem that can arise when using Bayesian estimation in this
context is “label switching”, i.e., as the hidden states of the HMM have
no a priori ordering or interpretation, their labels (i.e., which state
represents what) can switch over the iterations of the Gibbs sampler,
without affecting the likelihood of the model <span class="citation">(see e.g., Scott 2002; Jasra, Holmes, and Stephens
2005)</span>. As a result, the marginal posterior distributions of the
parameters are impossible to interpret because they represent the
distribution of multiple states. Sometimes, using reasonable starting
values (i.e., the user-specified parameter values of the “zero-th”
iteration used to start the MCMC sampler) suffices to prevent label
switching. Otherwise, possible solutions are to set constraints on the
parameters of the state-dependent distribution, or use (weakly)
informative priors on the state-dependent distributions <span class="citation">(Scott 2002)</span>. Hence, before making inferences
from the obtained marginal distributions, one should first assess if the
problem of label switching is present (e.g., by using plots of the
sampled parameter values of the state-dependent distributions over the
iterations), and if necessary, take steps to prevent the problem of
label switching. In our own experience, the use of reasonable starting
values always sufficed to prevent label switching.</p>
<p>Both EM and Bayesian Gibbs sampling are viable inferential procedures
for HMMs, but for more complex HMMs such as multilevel HMMs, the
Bayesian estimation method has several advantages (e.g., lower
computational cost, and less computation time) over the EM algorithm. We
refer to <span class="citation">Rydén (2008)</span> for a comparison on
frequentist (i.e., the EM algorithm) and Bayesian approaches.</p>
</div>
</div>
<div id="estimating-the-parameters-of-the-multilevel-hmm" class="section level1">
<h1>Estimating the parameters of the multilevel HMM</h1>
<div id="bayesian-estimation-of-multilevel-models" class="section level2">
<h2>Bayesian estimation of multilevel models</h2>
<p>Bayesian estimation is particularly suited to model multilevel
models. In the multilevel model, we have a multi-layered structure in
the parameters. For the HMM, we have subject level parameters at the
first level pertaining to the observations within a subject, and group
level parameters at the second level that describe the mean and
variation within the group, as inferred from the sample of subjects. To
illustrate the multilevel model, suppose that we have <span class="math inline">\(K\)</span> subjects for which we have each <span class="math inline">\(H\)</span> observations on their number of cups of
coffee consumed per day <span class="math inline">\(y\)</span>, i.e.,
subject <span class="math inline">\(k \in \{1, 2, \ldots, K\}\)</span>
and observation <span class="math inline">\(h \in \{1, 2, \ldots,
H\}\)</span>. Hence, at the first level, we have daily observations on
coffee consumption within subjects: <span class="math inline">\(y_{11}\)</span>, <span class="math inline">\(y_{12}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(y_{1H}\)</span>, <span class="math inline">\(y_{21}\)</span>, <span class="math inline">\(y_{22}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(y_{2H}\)</span>, <span class="math inline">\(y_{K1}\)</span>, <span class="math inline">\(y_{K2}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(y_{KH}\)</span>. Using a multilevel model, the
observations of each subject are distributed according to the same
distribution <span class="math inline">\(Q\)</span>, but each subject
has its own parameter set <span class="math inline">\(\theta_k\)</span>.
That is:</p>
<p><span class="math display">\[\begin{equation}
y_{kh} \sim Q(\theta_k).
\end{equation}\]</span></p>
<p>In addition, the subject-specific parameter sets <span class="math inline">\(\theta_k\)</span> are realizations of a common
group level distribution <span class="math inline">\(W\)</span> with
parameter set <span class="math inline">\(\Lambda\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\theta_k \sim W(\Lambda).
\end{equation}\]</span></p>
<p>That is, in the multilevel model, the subject level model parameters
that pertain to the observations within a subject are assumed to be
random draws from a given distribution, and, as such, are denoted as
“random”, independent of the used estimation method (i.e., Bayesian or
classical frequentist estimation). This multi-layered structure fits
naturally into a Bayesian paradigm since in Bayesian estimation, model
parameters are by definition viewed as random. That is, parameters
follow a given distribution, where the prior distribution expresses the
prior expectations with respect to the most likely values of the model
parameters. In the multilevel model, the prior expectations of the
subject level model parameter values are reflected in the group level
distribution. Hence, in Bayesian estimation, the prior distribution for
the subject level parameters, is given by the group level distribution.
The group level distribution provides information on the location (e.g.,
mean) of the subject level (i.e., subject-specific) parameters, and on
the variation in the subject level parameters. As the Normal
distribution is a flexible distribution with parameters that easily
relate to this interpretation, the group level distribution is often
taken to be a normal distribution.</p>
<p>To illustrate the notion of the group level (prior) distribution,
suppose we assume a Poisson distribution for the observations on daily
coffee consumption within each subject k, and a Normal group level
distribution on the Poisson mean. In this case, the set of
hyper-parameters (i.e., the parameters of the group level distribution,
here the mean (<span class="math inline">\(\Lambda_\mu\)</span>) and
variance (<span class="math inline">\(\Lambda_{\sigma^2}\)</span>) of
the Normal distribution) on the Poisson mean denote the group mean
number of cups of coffee consumed per day over subjects, and the
variation in the mean number of cups of coffee consumed per day between
subjects.</p>
<p>Finally, in fitting the multilevel model using Bayesian estimation, a
prior distribution is placed on each of these hyper-parameters. Prior
distributions on hyper-parameters are referred to as hyper-priors and
allow the hyper-parameters to have a distribution instead of being
fixed. That is, as the parameters that characterize the group level
prior distribution (i.e., the hyper-parameters) are now also quantities
of interest (i.e., to-be-estimated), they are viewed as random in
Bayesian estimation methods. The randomness in the hyper-parameters is
thus specific to the Bayesian estimation method of the multilevel model,
in contrast to the randomness in the subject level parameters.</p>
<p>To continue our example, the hyper-prior on the mean of the Normal
prior distribution for the subject level mean of cups of coffee consumed
daily denote our prior belief on the mean number of cups of coffee
consumed per day in the group. The hyper-prior on the variance of the
Normal prior distribution for the subject level mean of cups of coffee
consumed per day denote our prior belief on how much this mean number of
cups of coffee varies over subjects. Often, the hyper-prior distribution
and its values are chosen to be vague (i.e., not informative), like a
uniform distribution:</p>
<p><span class="math display">\[\begin{align}
\Lambda_\mu &amp; \: \sim U(0, 20),\\ \nonumber
\Lambda_{\sigma^2} &amp; \:  \sim U(0, 500).
\end{align}\]</span></p>
<p>See e.g., <span class="citation">Gelman et al. (2014)</span>, <span class="citation">Lynch (2007)</span>, <span class="citation">Rossi,
Allenby, and McCulloch (2012)</span> for an in-depth exposition of
various multilevel Bayesian models and e.g. <span class="citation">Snijders and Bosker (2011)</span>, <span class="citation">Hox, Moerbeek, and Schoot (2017)</span>, <span class="citation">Goldstein (2011)</span> for coverage of the classical,
frequentist approach to multilevel (also called hierarchical or random
effects) models.</p>
<p>The present implemented multilevel model pertains only to data
comprised of (multivariate) categorical observations, and, possibly,
time invariant covariates (i.e., for each covariate, we have one value
per subject). As such, data is comprised of <span class="math inline">\(O_{d, k, t}\)</span> observations on the
categorical outcome(s) for categorical outcome variable <span class="math inline">\(d = 1, 2, \ldots, D\)</span> for subject <span class="math inline">\(k = 1, 2, \ldots, K\)</span> at time point <span class="math inline">\(t = 1, 2, \ldots, T\)</span>. In addition, we have
a matrix <span class="math inline">\(\boldsymbol{X}\)</span> that
consists of <span class="math inline">\(k\)</span> covariate vectors
with length <span class="math inline">\(p \times 1\)</span>, <span class="math inline">\(\boldsymbol{X}_k = (X_{k1}, X_{k2}, \ldots,
X_{kp})\)</span>. As yet, the explanation of the estimation procedure in
this vignette is restricted to the univariate case for simplicity. That
is, to the instance that we only have one observed categorical outcome
variable per subject, and our outcome data is comprised of <span class="math inline">\(O_{kt}\)</span> observations. However, the
explanation extents quite naturally to the multivariate case.</p>
<p>Given these observations, we construct a multilevel model for each of
the parameters in the HMM with <span class="math inline">\(q\)</span>
observable categorical outcomes, and <span class="math inline">\(m\)</span> hidden states, possibly predicted by
<span class="math inline">\(p\)</span> covariates. Using the multilevel
framework, each parameter is assumed to follow a given distribution, and
the parameter value of a given subject represents a draw from this
common (i.e., group level) distribution. Hence, in the multilevel
Bayesian HMM, the parameters are: the subject-specific transition
probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span> with transition
probabilities <span class="math inline">\(\gamma_{kij}\)</span> and the
subject-specific state-dependent probability distribution denoting the
subject-specific probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> of categorical
outcomes within state <span class="math inline">\(i\)</span>. The
initial probabilities of the states <span class="math inline">\(\pi_{k,j}\)</span> are not estimated as <span class="math inline">\(\pi_{k}\)</span> is assumed to be the stationary
distribution of <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span>. Subsequently, the
parameter values of the subjects are assumed to be realizations of a
model component and state specific (multivariate) Normal distribution.
We discuss the multilevel model for the two components of the HMM (<span class="math inline">\(\boldsymbol{\Gamma}_k\)</span> and <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> separately.
Below we provide an overview of the used symbols in the multilevel
models related to the two components of the HMM. We use the subscript 0
to denote values of the hyper-prior distribution parameters.</p>
<hr />
<ul>
<li><p><span class="math inline">\(k\)</span>: subject <span class="math inline">\(k \in \{1, 2, \ldots, K \}\)</span>, where <span class="math inline">\(K\)</span> is the total number of subjects in the
dataset.</p></li>
<li><p><span class="math inline">\(t\)</span>: Time point <span class="math inline">\(t \in \{1, 2, \ldots, T \}\)</span>, where <span class="math inline">\(T\)</span> is the total length of each sequence of
observations. In the current notation, <span class="math inline">\(T\)</span> is assumed equal over subjects. Within
the R package mHMMbayes this is not a requirement, however.</p></li>
<li><p><span class="math inline">\(q\)</span>: Number of distinct
observation categories.</p></li>
<li><p><span class="math inline">\(m\)</span>: Number of distinct
states.</p></li>
<li><p><span class="math inline">\(p\)</span>: Number of (time
invariant) covariates.</p></li>
<li><p><span class="math inline">\(O_{kt}\)</span>: Observation on the
categorical outcome for subject <span class="math inline">\(k\)</span>
at time point <span class="math inline">\(t\)</span>.</p></li>
<li><p><span class="math inline">\(S_{kt}\)</span>: State for subject
<span class="math inline">\(k\)</span> at time point <span class="math inline">\(t\)</span> for <span class="math inline">\(S \in
\{1, 2, \ldots, m \}\)</span>.</p></li>
<li><p><span class="math inline">\(i\)</span>: Realization of the
current state <span class="math inline">\(S_t\)</span>, where <span class="math inline">\(i \in \{1, 2, \ldots , m\}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{X}\)</span>: Matrix of
<span class="math inline">\(k\)</span> covariate vectors with length
<span class="math inline">\(p \times 1\)</span>, <span class="math inline">\(\boldsymbol{X}_k = (X_{k1}, X_{k2}, \ldots,
X_{kp})\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\Gamma_k} =
[\gamma_{kij}]\)</span>: Subject-specific transition probability matrix
between states with the probabilities <span class="math inline">\(\gamma_{kij}\)</span> of transitioning from state
<span class="math inline">\(S_{kt} = i\)</span> to state <span class="math inline">\(S_{k(t+1)} = j\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>:
subject <span class="math inline">\(k\)</span> and state <span class="math inline">\(i\)</span> specific batch of <span class="math inline">\(m-1\)</span> random intercepts that model the
transitions from state <span class="math inline">\(i\)</span> to the
next state <span class="math inline">\(j\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span>: State
<span class="math inline">\(i\)</span> specific group mean vector over
the subject <span class="math inline">\(k\)</span> batches of the <span class="math inline">\(m-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>:
State <span class="math inline">\(i\)</span> specific fixed regression
coefficients to predict the random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\Psi_i\)</span>: State <span class="math inline">\(i\)</span> specific covariance between the subject
<span class="math inline">\(k\)</span> batches of the <span class="math inline">\(m-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span>,
<span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span>, <span class="math inline">\(K_0\)</span>: Values of the parameters of the
hyper-prior on the group mean vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span> and
fixed regression coefficients <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> .</p></li>
<li><p><span class="math inline">\(\Psi_0\)</span>, <span class="math inline">\(df_0\)</span>: Values of the parameters of the
hyper-prior on the group covariance <span class="math inline">\(\Psi_i\)</span>.</p></li>
<li><p><span class="math inline">\(O_{kt}\)</span>: Observed event for
subject <span class="math inline">\(k\)</span> at time point <span class="math inline">\(t\)</span> for <span class="math inline">\(O \in
\{1, 2, \ldots q\}\)</span>.</p></li>
<li><p><span class="math inline">\(l\)</span>: Realization of current
event <span class="math inline">\(O_{kt}\)</span>, where <span class="math inline">\(l \in \{1, 2, \ldots, q \}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\theta}_{ki} =
[\theta_{kil}]\)</span>: Subject-specific state <span class="math inline">\(i\)</span> categorical conditional distribution,
with the probabilities <span class="math inline">\(\text{p}_{kil}\)</span> of observing the
categorical outcome <span class="math inline">\(O_{kt} = l\)</span> in
state <span class="math inline">\(S_{kt} = i\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>:
Subject <span class="math inline">\(k\)</span> state <span class="math inline">\(i\)</span> specific batch of <span class="math inline">\(q-1\)</span> random intercepts that model the
probability of a categorical outcome <span class="math inline">\(O_{kt}\)</span> within state <span class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span>: State
<span class="math inline">\(i\)</span> specific group mean vector over
the subject <span class="math inline">\(k\)</span> batches of the <span class="math inline">\(q-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>:
State <span class="math inline">\(i\)</span> specific fixed regression
coefficients to predict the subject-specific random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\Phi_{i}\)</span>: State <span class="math inline">\(i\)</span> specific covariance between the subject
<span class="math inline">\(k\)</span> batches of the <span class="math inline">\(q-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span>,
<span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span>, <span class="math inline">\(K_0\)</span>: Values of the parameters of the
hyper-prior on the group mean vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and the
fixed regression coefficients <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>.</p></li>
<li><p><span class="math inline">\(\Phi_0\)</span>, <span class="math inline">\(df_0\)</span>: Values of the parameters of the
hyper-prior on the group covariance <span class="math inline">\(\Phi_{i}\)</span>.</p></li>
</ul>
<hr />
</div>
<div id="multilevel-model-for-the-state-dependent-probabilities-boldsymboltheta_ki" class="section level2">
<h2>Multilevel model for the state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span></h2>
<p>In the standard (non-multilevel) Bayesian HMM estimation, we
specified a Dirichlet prior distribution on the state-dependent
probabilities <span class="math inline">\(\boldsymbol{\theta}_{i}\)</span>. To provide a
flexible model that allows for the inclusion of random effects and (time
invariant) covariates, we follow <span class="citation">Altman
(2007)</span> and extend the subject-specific state-dependent
probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> to a Multinomial
logit (MNL) model. Hence, we utilize a linear predictor function to
estimate the probability of observing categorical outcome <span class="math inline">\(l\)</span> within state <span class="math inline">\(i\)</span>. The state <span class="math inline">\(i\)</span> specific linear predictor function at
the subject level consists of <span class="math inline">\(q-1\)</span>
random intercepts (i.e., each subject has its own intercept). That is,
each categorical outcome <span class="math inline">\(l\)</span> has its
own intercept, with the exception of the first categorical outcome in
the set for which the intercept is omitted for reasons of model
identification (i.e., not all probabilities can be estimated freely as
within subject <span class="math inline">\(k\)</span> and state <span class="math inline">\(i\)</span>, the probabilities need to add up to
1). By making the intercepts random (i.e., each subject has its own
intercept), we accommodate heterogeneity between subjects in their state
conditional probabilities. Hence, in the MNL model for <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span>, subject <span class="math inline">\(k\)</span>’s probabilities of observing
categorical outcome <span class="math inline">\(l \in \{1, 2, \ldots, q
\}\)</span> within a state <span class="math inline">\(i \in \{1, 2,
\ldots , m\}\)</span>, <span class="math inline">\({\theta}_{kil}\)</span>, are modeled using <span class="math inline">\(m\)</span> batches of <span class="math inline">\(q-1\)</span> random intercepts, <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki} = (\alpha_{(O)ki2},
\alpha_{(O)ki3}, \ldots, \alpha_{(O)kiq})\)</span>. That is,</p>
<p><span class="math display">\[\begin{equation}
{\theta}_{kil} = \frac{\text{exp}(\alpha_{(O)kil})}{1 + \sum_{\bar{l} =
2}^q \text{exp}(\alpha_{(O)ki\bar{l}})},
\end{equation}\]</span></p>
<p>where <span class="math inline">\(K\)</span>, <span class="math inline">\(m\)</span>, and <span class="math inline">\(q\)</span> are the number of subjects, states, and
categorical outcomes, respectively. The numerator is set equal to one
for <span class="math inline">\(l = 1\)</span>, making the first
categorical outcome in the set the baseline category in every
state.<br />
At the group level, these subject-level intercepts are (possibly) partly
determined by covariates that differentiate between subjects. Thus, in
addition to the subject level random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>, we have
<span class="math inline">\(m\)</span> matrices of <span class="math inline">\(p * (q-1)\)</span> fixed regression coefficients,
<span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>, where
<span class="math inline">\(p\)</span> denotes the number of used
covariates. The columns of <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> are <span class="math inline">\(\boldsymbol{\beta}_{(O)il} = (\beta_{(O)il1},
\beta_{(O)il2}, \ldots, \beta_{(O)ilp})\)</span> to model the random
intercepts for state <span class="math inline">\(i\)</span> and
categorical outcome <span class="math inline">\(l\)</span> given <span class="math inline">\(p\)</span> covariates. Combining both terms, each
batch of random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> (i.e., the
batch of <span class="math inline">\(q-1\)</span> intercepts for the
state <span class="math inline">\(i\)</span> conditional probabilities
of a categorical outcome for subject <span class="math inline">\(k\)</span>) come from a state <span class="math inline">\(i\)</span> specific population level multivariate
Normal distribution, with mean vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i} +
\boldsymbol{X_{k}^\top} \boldsymbol{\beta_{(O)il}}\)</span> that has
length <span class="math inline">\(q-1\)</span>, and covariance <span class="math inline">\(\Phi_{i}\)</span> that denotes the covariance
between the <span class="math inline">\(q-1\)</span> state <span class="math inline">\(i\)</span> specific intercepts over subjects and
models the dependence of the probabilities of categorical outcomes
within state <span class="math inline">\(i\)</span> (i.e., we specify a
state specific multivariate Normal prior distribution on the
subject-specific <span class="math inline">\(\boldsymbol{\alpha_{(O)ki}}\)</span> parameters).
A convenient hyper-prior on the hyper-parameters of the group level
prior distribution is a multivariate Normal distribution for the mean
vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and the
fixed regression coefficients <span class="math inline">\(\boldsymbol{\beta_{(O)il}}\)</span>, and an
Inverse Wishart distribution for the covariance <span class="math inline">\(\Phi_{i}\)</span> <span class="citation">(see
e.g., Gelman et al. 2014)</span>. That is,</p>
<p><span class="math display">\[\begin{align}
O_{kt} \: \sim \boldsymbol{\theta}_{k, S_{kt}}  &amp; \quad \text{with}
\quad \boldsymbol{\theta}_{ki} \: \sim
\text{MNL}\big(\boldsymbol{\alpha}_{(O)ki}\big), \label{pPriorHier}\\
\boldsymbol{\alpha}_{(O)ki}     \: \sim
\text{N}\big(\boldsymbol{\bar{\alpha}}_{(O)i} + \boldsymbol{X_{k}^\top}
\boldsymbol{\beta_{(O)il}}, \Phi_{i}\big)   &amp; \quad \text{with}
\quad  \boldsymbol{\bar{\alpha}}_{(O)i} \: \sim
\text{N}\big(\boldsymbol{\alpha}_{(O)0}, \tfrac{1}{K_0}\Phi_{i} \big),
\label{popPHier}\\
                        &amp; \quad \text{and}
\quad  \boldsymbol{\beta}_{(O)i} \: \sim
\text{N}\big(\boldsymbol{\beta}_{(O)0}, \tfrac{1}{K_0}\Phi_{i} \big), \\
                                                &amp; \quad \text{and}
\quad  \: \Phi_{i} \: \sim \text{IW}\big(\Phi_0, df_0 \big),
\nonumber                               
\end{align}\]</span></p>
<p>where the probability distribution of the observed categorical
outcomes <span class="math inline">\(O_{kt}\)</span> is given by the
subject <span class="math inline">\(k\)</span> specific state-dependent
probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> corresponding to
the current state <span class="math inline">\(S_{kt}\)</span> (where
<span class="math inline">\(t\)</span> indicates the time point). The
parameters <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span>, and <span class="math inline">\(K_0\)</span> denote the values of the parameters
of the hyper-prior on the group (mean) vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>,
respectively. Here, <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span> represent a
vector of means and <span class="math inline">\(K_0\)</span> denotes the
number of observations (i.e., the number of hypothetical prior subjects)
on which the prior mean vector <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span> are based,
i.e., <span class="math inline">\(K_0\)</span> determines the weight of
the prior on <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>. The
parameters <span class="math inline">\(\Phi_0\)</span> and <span class="math inline">\(df_0\)</span>, respectively, denote the values of
the covariance and the degrees of freedom of the hyper-prior Inverse
Wishart distribution on the population variance <span class="math inline">\(\Phi_{i}\)</span> of the subject-specific random
intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>. Note that we
chose the values of the parameters of the hyper-prior distributions that
result in uninformative hyper-prior distributions, as such the values of
the parameters of the hyper-priors are assumed invariant over the states
<span class="math inline">\(i\)</span>.</p>
</div>
<div id="multilevel-model-for-the-transition-probability-matrix-boldsymbolgamma_k-with-transition-probabilities-boldsymbolgamma_kij" class="section level2">
<h2>Multilevel model for the transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma_k}\)</span> with transition
probabilities <span class="math inline">\(\boldsymbol{\gamma_{kij}}\)</span></h2>
<p>Similar to the state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span>, we extend each
set of state <span class="math inline">\(i\)</span> specific state
transition probabilities <span class="math inline">\(\gamma_{kij}\)</span> to a MNL model to allow for
the inclusion of random effects and (time invariant) covariates. Hence,
we use a linear predictor function to estimate the probability to
transition from behavioral state <span class="math inline">\(i\)</span>
to state <span class="math inline">\(j\)</span>. The linear predictor
function consists of <span class="math inline">\(m-1\)</span> random
intercepts to allow for heterogeneity between subjects in their
probabilities to switch between states. That is, within row <span class="math inline">\(i\)</span> of the transition probability matrix
<span class="math inline">\(\boldsymbol{\Gamma_k}\)</span>, each state
<span class="math inline">\(j\)</span> has its own intercept, where the
intercept that relates to transitioning to the first state in the set is
omitted for reasons of model identification (i.e., not all probabilities
can be estimated freely as the row-probabilities need to add up to 1).
Hence, each subject’s probability to transition from behavioral state
<span class="math inline">\(i \in\{1, 2, \ldots, m \}\)</span> to state
<span class="math inline">\(j \in \{1, 2, \ldots, m \}\)</span> is
modeled using <span class="math inline">\(m\)</span> batches of <span class="math inline">\(m-1\)</span> random intercepts, <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki} = (\alpha_{(S)k13},
\ldots, \alpha_{(S)k1m}, \alpha_{(S)k23}, \ldots,
\alpha_{(S)k2m},\)</span> <span class="math inline">\(\ldots,
\alpha_{(S)km2},\)</span> <span class="math inline">\(\dots,\)</span>
<span class="math inline">\(\alpha_{(S)km(m-1)})\)</span>. That is,</p>
<p><span class="math display">\[\begin{equation}
\gamma_{kij} = \frac{\text{exp}(\alpha_{(S)kij})}{1 + \sum_{\bar{j} \in
Z} \text{exp}(\alpha_{(S)ki\bar{j}})},
\end{equation}\]</span> <span class="math display">\[\begin{equation}
\text{where} \ Z \in \{2, \ldots, m\} \nonumber
\end{equation}\]</span></p>
<p>where <span class="math inline">\(K\)</span> and <span class="math inline">\(m\)</span> are again the number of subjects in the
dataset, and the distinct number of states, respectively. The numerator
is set equal to 1 for <span class="math inline">\(j = 1\)</span>, making
the first state of every row of the transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span> the baseline
category.</p>
<p>At the group level, these subject-level intercepts are (possibly)
partly determined by covariates that differentiate between subjects.
Thus, in addition to the subject level random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, we have
<span class="math inline">\(m\)</span> matrices of <span class="math inline">\(p * (q-1)\)</span> fixed regression coefficients,
<span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>, where
<span class="math inline">\(p\)</span> denotes the number of used
covariates. The columns of <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> are <span class="math inline">\(\boldsymbol{\beta}_{(S)ij} = (\beta_{(S)ij1},
\beta_{(S)ij2}, \ldots, \beta_{(S)ijp})\)</span> to model the random
intercepts denoting the probability of transitioning from behavioral
state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> given <span class="math inline">\(p\)</span> covariates. Combining both terms, each
batch of random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> come from a
state <span class="math inline">\(i\)</span> specific population level
multivariate Normal distribution, with mean vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i} +
\boldsymbol{X_{k}^\top} \boldsymbol{\beta_{(S)ij}}\)</span> that has
length <span class="math inline">\(q-1\)</span>, and covariance <span class="math inline">\(\Psi_i{i}\)</span> that denotes the covariance
between the <span class="math inline">\(q-1\)</span> state <span class="math inline">\(i\)</span> specific intercepts over subjects, and
models the dependency between the probabilities of states within random
intercept batch <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> (i.e., we
specify a state specific multivariate Normal prior distribution on the
subject-specific <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> parameters).
A convenient hyper-prior on the hyper-parameters of the group level
prior distribution is a multivariate Normal distribution for the mean
vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span> and the
fixed regression coefficients <span class="math inline">\(\boldsymbol{\beta_{(S)il}}\)</span> and an Inverse
Wishart distribution for the covariance <span class="math inline">\(\Psi_i\)</span>. That is,</p>
<p><span class="math display">\[\begin{align}
S_{k, t = 2, \ldots, T} \: \sim \boldsymbol{\Gamma}_{k, S_{k, t-1}}
\quad &amp;\text{with} \quad \boldsymbol{\Gamma}_{k, i}  \: \sim
\text{MNL}\big(\boldsymbol{\alpha}_{(S)ki}\big), \label{tpmPriorHier}\\
\boldsymbol{\alpha}_{(S)ki} \: \sim
\text{N}\big(\boldsymbol{\bar{\alpha}}_{(S)i} + \boldsymbol{X_{k}^\top}
\boldsymbol{\beta_{(S)il}}, \Psi_i\big) \quad &amp;\text{with}
\quad   \boldsymbol{\bar{\alpha}}_{(S)i} \: \sim
\text{N}\big(\boldsymbol{\alpha}_{(S)0}, \tfrac{1}{K_0}\Psi_i
\big),  \label{popTmpHier} \\
        &amp;\text{and} \quad  \boldsymbol{\beta}_{(S)i} \: \sim
\text{N}\big(\boldsymbol{\beta}_{(S)0}, \tfrac{1}{K_0}\Psi_{i} \big), \\
        &amp;\text{and} \quad \:   \Psi_i \: \sim \text{IW}\big(\Psi_0,
df_0 \big), \nonumber
\end{align}\]</span></p>
<p>where the subject-specific probability distribution of the current
state <span class="math inline">\(S_{kt}\)</span> is given by the row of
the transition probability matrix <span class="math inline">\(\mathbf{\Gamma}_k\)</span> corresponding to the
previous state in the hidden state sequence <span class="math inline">\(S_{k, t-1}\)</span>. The probability distribution
of <span class="math inline">\(S_{kt}\)</span> given by <span class="math inline">\(\mathbf{\Gamma}_k\)</span> holds for states after
the first time point, i.e., <span class="math inline">\(t\)</span>
starts at 2 as there is no previous state in the hidden state sequence
for state <span class="math inline">\(S_{kt}\)</span> at <span class="math inline">\(t\)</span> = 1. The probability of the first state
in the hidden state sequence <span class="math inline">\(S_{k,1}\)</span> is given by the initial
probabilities of the states <span class="math inline">\(\pi_{k,j}\)</span>. The parameters <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span>, and <span class="math inline">\(K_0\)</span> denote the values of the parameters
of the hyper-prior on the group (mean) vector <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span> and
<span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>,
respectively. Here, <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span> represent a
vector of means and <span class="math inline">\(K_0\)</span> denotes the
number of observations (i.e., the number of hypothetical prior subjects)
on which the prior mean vector <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span> are based. The
parameters <span class="math inline">\(\Psi_0\)</span> and <span class="math inline">\(df_0\)</span>, respectively, denote values of the
covariance and the degrees of freedom of the hyper-prior Inverse Wishart
distribution on the group variance <span class="math inline">\(\Psi_i\)</span> of the subject-specific random
intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>.</p>
</div>
</div>
<div id="hybrid-metropolis-within-gibbs-sampler-used-to-fit-the-multilevel-hmm" class="section level1">
<h1>Hybrid Metropolis within Gibbs sampler used to fit the multilevel
HMM</h1>
<p>Given the above distributions, our goal is to construct the joint
posterior distribution of the parameters - i.e., the subject-specific
hidden state sequences, the subject level (i.e., subject-specific)
parameters and the group level parameter estimates - given the
observations (i.e., the observed event sequences for all <span class="math inline">\(k\)</span> subjects that are analyzed
simultaneously as one group, and the hyper-prior parameter values)</p>
<p><span class="math display">\[\begin{align}
&amp; \Pr\big(S_{kt}, \mathbf{\Gamma}_{ki}, \boldsymbol{\alpha}_{(S)ki},
\boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{\beta}_{(S)i}, \Psi_i,
\boldsymbol{\theta}_{ki}, \boldsymbol{\alpha}_{(O)ki},
\boldsymbol{\bar{\alpha}}_{(O)i},\boldsymbol{\beta}_{(O)ki}, \Phi_{i}
\mid O_{kt}, \boldsymbol{X}\big) \nonumber \\
&amp; \quad \propto \Pr\big(O_{kt} \mid
S_{kt},  \boldsymbol{\theta}_{ki}\big)  \Pr\big(S_{kt} \mid
\mathbf{\Gamma}_{ki}\big) \Pr\big( \boldsymbol{\theta}_{i} \mid
\boldsymbol{\alpha}_{(O)ki} \big)  \Pr\big(\mathbf{\Gamma}_i  \mid
\boldsymbol{\alpha}_{(S)ki} \big)  \Pr\big( \boldsymbol{\alpha}_{(O)ki}
\mid \boldsymbol{\bar{\alpha}}_{(O)i}, \boldsymbol{X},
\boldsymbol{\beta}_{(O)i}, \Phi_{i}\big) \nonumber \\
&amp; \quad \quad \quad \quad \Pr\big(\boldsymbol{\alpha}_{(S)ki}
\mid  \boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{X},
\boldsymbol{\beta}_{(S)i}, \Psi_i \big)
\Pr\big(\boldsymbol{\bar{\alpha}}_{(O)i}
\mid  \boldsymbol{\alpha}_{(O)0}, K_0, \Phi_i \big)
\Pr\big(\boldsymbol{{\beta}}_{(O)i} \mid  \boldsymbol{\beta}_{(O)0},
K_0, \Phi_i \big)  \Pr\big(\Phi_{i} \mid \Phi_0, df_0 \big) \nonumber \\
&amp;  \quad  \quad   \quad \quad \quad \quad
\Pr\big(\boldsymbol{\bar{\alpha}}_{(S)i}
\mid  \boldsymbol{\alpha}_{(S)0}, K_0, \Psi_{i} \big)
\Pr\big(\boldsymbol{{\beta}}_{(S)i} \mid  \boldsymbol{\beta}_{(S)0},
K_0, \Psi_{i} \big) \Pr\big(\Psi_i \mid \Psi_0, df_0 \big)   \nonumber
\\
\end{align}\]</span></p>
<p>by drawing samples from the posterior distribution. We follow a MCMC
sampler algorithm to iteratively sample from the appropriate conditional
posterior distributions of <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>, <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span>, <span class="math inline">\(\boldsymbol{{\beta}}_{(O)i}\)</span>, <span class="math inline">\(\Phi_{i}\)</span>, <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span>, <span class="math inline">\(\boldsymbol{{\beta}}_{(S)i}\)</span>, and <span class="math inline">\(\Psi_i\)</span> given the remaining parameters in
the model (see below). The conditional posterior distributions of all
parameters are provided in the Section “”.</p>
<p>In Bayesian estimation, it is preferable to use the natural conjugate
prior as prior distribution, as this conveniently results in a closed
form expression of the (conditional) posterior distribution(s), making
Gibbs sampling possible. However, as the non-conjugate Normal prior
provides a much more intuitive interpretation of the prior group level
distribution compared to using the natural conjugate prior of the MNL
model, and since the asymptotic Normal approximation is excellent for
the MNL likelihood <span class="citation">(Rossi, Allenby, and McCulloch
2012)</span>, we opt for the former and do not use the conjugate prior
of the MNL model. Therefore, we cannot use a Gibbs sampler to update the
parameters of the subject-specific state-dependent distributions and the
subject-specific transition probabilities, <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>,
respectively. Instead, we use a combination of the Gibbs sampler and the
Metropolis algorithm, i.e., a Hybrid Metropolis within Gibbs sampler.
That is, we use a Metropolis sampler to update <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, and we use a
Gibbs sampler to update all other model parameters. There are various
types of Metropolis algorithms, and each type involves specific choices.
Simulation studies showed that, in line with <span class="citation">Rossi, Allenby, and McCulloch (2012)</span>, the Random
Walk (RW) Metropolis sampler outperformed the Independence Metropolis
sampler in terms of efficiency for estimating the parameters of the
(multilevel) HMM, we chose to use the RW Metropolis sampler to update
the parameters of the subject-specific state-dependent distributions
(<span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>) and
subject-specific state transition probabilities (<span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>) in our
Hybrid Metropolis within Gibbs sampler.</p>
<p>The Hybrid Metropolis within Gibbs sampler for the multilevel HMM
proceeds in a similar fashion as the Gibbs sampler for the HMM: first
the hidden state sequences are sampled (for each subject separately),
after which the (subject level and group level) parameters are sampled
given the observed event sequence (for each subject, <span class="math inline">\(O_{kt}\)</span>), the sampled hidden state
sequences (of each subject, <span class="math inline">\(S_{kt}\)</span>), and the current values of the
remaining parameters in the model. We provide a stepwise walkthrough of
the hybrid Metropolis within Gibbs sampler for the multilevel HMM
below.</p>
<div id="stepwise-walkthrough-of-the-used-hybrid-metropolis-within-gibbs-sampler" class="section level2">
<h2>Stepwise walkthrough of the used hybrid Metropolis within Gibbs
sampler</h2>
<p>The Hybrid Metropolis within Gibbs sampler used to fit the multilevel
HMM proceeds as described below. We use the subscript <span class="math inline">\(c\)</span> to denote the current (i.e., updated
using a combination of the value of the hyper-prior and the data)
parameters of the conditional posterior distributions.</p>
<ul>
<li>Given the observed event sequence for each subject <span class="math inline">\(k\)</span> <span class="math inline">\(O_{k1},
O_{k2}, \ldots, O_{kT}\)</span> and the current values of the parameters
<span class="math inline">\(\mathbf{\Gamma}\)</span> and <span class="math inline">\(\boldsymbol{\theta}_i\)</span>, a hidden state
sequence <span class="math inline">\(S_{k1}, S_{k2}, \ldots,
S_{kT}\)</span> is sampled for each subject separately, utilizing the
forward probabilities. Note that for each subject <span class="math inline">\(k \in \{1, 2, \ldots, K\}\)</span>, the
subject-specific parameters (i.e., <span class="math inline">\(\mathbf{\Gamma}_{ki}\)</span> and <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span>) are used as
input for the forward-backward recursions. For the first run of the
algorithm, user-specified start values are used for the subject-specific
parameters <span class="math inline">\(\mathbf{\Gamma}_{ki}\)</span> and
<span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span>.</li>
<li>Given the current subject-specific sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> (related to
the subject-specific state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> and the
subject-specific state transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span>, respectively) and
the observed (time invariant) covariates <span class="math inline">\(\boldsymbol{X}\)</span>, new parameter estimates
are drawn for the group mean and covariance of the subject-specific sets
of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> and the fixed
regression coefficients <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> from their
conditional posterior distributions <span class="math inline">\(\Pr(\boldsymbol{\bar{\alpha}}_{(O)i},
\boldsymbol{\beta}_{(O)i} \mid\ )\)</span>, <span class="math inline">\(\Pr(\Phi_{i} \mid \ )\)</span>, <span class="math inline">\(\Pr(\boldsymbol{\bar{\alpha}}_{(S)i},
\boldsymbol{\beta}_{(S)i} \mid \ )\)</span>, and <span class="math inline">\(\Pr(\Psi_i \mid \ )\)</span>, respectively. <br />
That is, first the state <span class="math inline">\(i\)</span> specific
group variance-covariance matrices <span class="math inline">\(\Phi_{i}\)</span> and <span class="math inline">\(\Psi_i\)</span> (i.e., the covariance between
intercepts for the state i and subject k specific intercept vector <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> or <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>) are drawn
from <span class="math inline">\(\Pr(\Phi_{i} \mid \ ) \sim
\text{IW}(\Phi_{ci}, df_c)\)</span> and <span class="math inline">\(\Pr(\Psi_i \mid \ ) \sim \text{IW}(\Psi_{ci}, df_c
)\)</span>, where <span class="math inline">\(\Phi_{ci}\)</span> and
<span class="math inline">\(\Psi_{ci}\)</span> represent a combination
of the chosen prior values <span class="math inline">\(\Phi_0\)</span>
and <span class="math inline">\(\Psi_0\)</span> and the state <span class="math inline">\(i\)</span> specific covariance observed over
subjects in <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>,
respectively, and <span class="math inline">\(df_{c}\)</span> represent
a combination of the chosen prior value <span class="math inline">\(df_{0}\)</span> and the number of subjects in the
analyzed subject dataset. See Gelman et al. (2014) for details on
updating the parameters of an Inverse Wishart distribution.<br /> Next,
the state <span class="math inline">\(i\)</span> specific mean group
estimates <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span>
are drawn simultaneously with the state <span class="math inline">\(i\)</span> specific fixed regression coefficient
<span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> from <span class="math inline">\(\Pr(\boldsymbol{\bar{\alpha}}_{(O)i},
\boldsymbol{\beta_{(O)i}} \mid\ \Phi_i,  \boldsymbol{\alpha}_{(S)ki},
\boldsymbol{X}) \sim \text{N}(\boldsymbol{\mu}_{(O)ci}, \tfrac{1}{K_c}
\Phi_{i})\)</span> and <span class="math inline">\(\Pr(\boldsymbol{\bar{\alpha}}_{(S)i},
\boldsymbol{\beta_{(S)i}} \mid \ \Psi_i,  \boldsymbol{\alpha}_{(S)ki},
\boldsymbol{X})  \sim \text{N}(\boldsymbol{\mu}_{(S)ci}, \tfrac{1}{K_c}
\Psi_i)\)</span>, where <span class="math inline">\(\boldsymbol{\mu}_{(O)ci}\)</span> and <span class="math inline">\(\boldsymbol{\mu}_{(S)ci}\)</span> represent a
combination of the chosen prior values <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span>, and <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span>, the observed
state <span class="math inline">\(i\)</span> specific mean vector over
subjects of the sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> and the least
squares estimators of <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>. The parameter
<span class="math inline">\(K_{c}\)</span> represents a combination of
the prior value <span class="math inline">\(K_{0}\)</span> and the
number of subjects in the analyzed dataset.</li>
<li>Given the observed event sequence for each subject <span class="math inline">\((O_{kt})\)</span>, the sampled hidden state
sequences of each subject <span class="math inline">\((S_{kt})\)</span>,
the group distributions for the subject-specific sets of intercepts
<span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and
<span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>
parameterized by <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\Phi_{i}\)</span>, and <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> and <span class="math inline">\(\Psi_i\)</span>, respectively, new estimates of
the subject-specific sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> are drawn
from their posterior conditional distribution <span class="math inline">\(\Pr(\boldsymbol{\alpha}_{(O)ki} \mid \ )\)</span>
and <span class="math inline">\(\Pr(\boldsymbol{\alpha}_{(S)ki} \mid \
)\)</span> using a Random Walk (RW) Metropolis sampler.<br /> That is, to
draw new estimates for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>, first a
candidate vector <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki
[candidate]}\)</span> is sampled from a proposal distribution, which we
chose to be an asymptotic normal approximation to the conditional
posterior distribution (see below). In the RW Metropolis sampler, the
vector of means of the proposal distribution is equal to the current
estimate of <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>, and the
scale of the distribution (i.e., here the covariance) has to be
specified by the user. To define the scale of the proposal distribution,
we followed the method outlined by Rossi, Allenby, and McCulloch (2012),
which is described below. In summary, we use a subject-specific scale
parameter <span class="math inline">\(\Sigma_{\alpha(O) ki}\)</span>,
which is a combination between the prior covariance (i.e., the group
covariance <span class="math inline">\(\Phi_{i}\)</span>), a covariance
matrix that captures the distribution of the data of the subjects (i.e.,
for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>,
this is the covariance in the observed outcomes within state <span class="math inline">\(i\)</span> for subject <span class="math inline">\(k\)</span>), and a scalar <span class="math inline">\(s^2\)</span>. Next, the candidate <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki [candidate]}\)</span>
drawn from the proposal distribution <span class="math inline">\(\text{N}(\boldsymbol{\alpha}_{(O)ki} ,
\Sigma_{\alpha(O) ki})\)</span> is accepted with the probability <span class="math inline">\(min(1, \rho_{\alpha(O)})\)</span>, where <span class="math inline">\(\rho_{\alpha(O)}\)</span> is the ratio between the
posterior conditional distribution evaluated at the candidate value and
the posterior conditional distribution evaluated at the current value:
<span class="math display">\[\begin{equation}
\rho_{\alpha(O)} = \frac
{L\big(\boldsymbol{\alpha}_{(O)ki [candidate]} \mid O_{kt}, S_{kt} =
i\big) \Pr\big(\boldsymbol{\alpha}_{(O)ki  [candidate]} \mid
\boldsymbol{\bar{\alpha}}_{(O)i}, \boldsymbol{X},
\boldsymbol{\beta_{(O)i}}, \Phi_{i}\big)}
{L\big(\boldsymbol{\alpha}_{(O)ki [current]} \mid O_{kt}, S_{kt} =
i\big) \Pr\big(\boldsymbol{\alpha}_{(O)ki  [current]}  \mid
\boldsymbol{\bar{\alpha}}_{(O)i}, \boldsymbol{X},
\boldsymbol{\beta_{(O)i}}, \Phi_{i}\big)}.
\end{equation}\]</span> If the candidate <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki [candidate]}\)</span>
is accepted, the candidate represents the new estimate for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>. If the
candidate is not accepted, the estimate for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> remains
unchanged. \ The new estimates for <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> are drawn in
a similar fashion: a candidate vector <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki [candidate]}\)</span>
is drawn from the proposal distribution <span class="math inline">\(\text{N}(\boldsymbol{\alpha}_{(S)ki} ,
\Sigma_{\alpha(S) ki})\)</span>, and accepted with the probability
min(1, <span class="math inline">\(\rho_{\alpha(S)}\)</span>): <span class="math display">\[\begin{equation}
\rho_{\alpha(S)} = \frac
{L\big(\boldsymbol{\alpha}_{(S)ki [candidate]} \mid S_{k,n}, S_{k,n-1} =
i \big) \Pr\big(\boldsymbol{\alpha}_{(S)ki  [candidate]} \mid
\boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{X},
\boldsymbol{\beta_{(S)i}}, \Psi_i\big)}
{L\big(\boldsymbol{\alpha}_{(S)ki [current]} \mid S_{k,n}, S_{k,n-1} =
i\big) \Pr\big(\boldsymbol{\alpha}_{(S)ki  [current]}  \mid
\boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{X},
\boldsymbol{\beta_{(S)i}}, \Psi_i\big)}.
\end{equation}\]</span> Note that the RW Metropolis sampler is repeated
for each subject <span class="math inline">\(k \in \{1, 2, \ldots,
K\}\)</span>.</li>
<li>RW Metropolis sampler is repeated for each subject <span class="math inline">\(k \in \{1, 2, \ldots, K\}\)</span>.</li>
</ul>
<p>These steps are repeated for a large number of iterations, and, after
discarding the first iterations as a “burn-in” period, the sampled
parameter estimates provide the empirical posterior distribution of the
model parameters.</p>
<p>Regarding the acceptance rate of the RW Metropolis sampler for the
subject-specific sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> (i.e.,
related to the subject-specific state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> and the
subject-specific state transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span>, respectively), an
acceptance rate of <span class="math inline">\(\sim23\%\)</span> is
considered optimal when many parameters are being updated at once <span class="citation">(Gelman et al. 2014)</span>. Within the R package
mHMMbayes, the number of accepted draws of a model are stored in
emiss_naccept and gamma_naccept for the conditional distributions and
the transition probabilities, respectively.</p>
</div>
<div id="scaling-the-proposal-distribution-of-the-rw-metropolis-sampler" class="section level2">
<h2>Scaling the proposal distribution of the RW Metropolis sampler</h2>
<p>To obtain the scale parameter <span class="math inline">\(\Sigma_{\alpha(O)ki}\)</span> and <span class="math inline">\(\Sigma_{\alpha(S) ki}\)</span> of the proposal
distributions of the RW Metropolis sampler for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>,
respectively, we followed the method outlined by <span class="citation">Rossi, Allenby, and McCulloch (2012)</span>, which has
several advantages as discussed below.<br />
The general challenge of the RW Metropolis sampler is that it has to be
“tuned” by choosing the scale of the symmetric proposal distribution
(e.g., the variance or covariance of a Normal or multivariate Normal
proposal distribution, respectively). The scale of the proposal
distribution is composed of a covariance matrix <span class="math inline">\(\Sigma\)</span>, which is then tuned by
multiplying it by a scaling factor <span class="math inline">\(s^2\)</span>. Hence we denote the scale of the
proposal distribution by <span class="math inline">\(s^2\Sigma\)</span>.
The scale <span class="math inline">\(s^2\Sigma\)</span> has to be set
such that the drawn parameter estimates cover the entire area of the
posterior distribution (i.e., the scale <span class="math inline">\(\Sigma\)</span> should not be set too narrow
because then only candidate parameters in close proximity of the current
parameter will be drawn), but remains reasonably efficient (i.e., the
scale <span class="math inline">\(\Sigma\)</span> should not be set too
wide because then many candidate parameters will be rejected resulting
in a slowly progressing chain of drawn parameter estimates).<br />
There are various options for the covariance matrix <span class="math inline">\(\Sigma\)</span>. Often, the covariance matrix
<span class="math inline">\(\Sigma\)</span> is set such that it
resembles the covariance matrix of the actual posterior distribution. To
capture the curvature of each subject’s conditional posterior
distribution, the scale of the RW Metropolis proposal distribution
should be customized to each subject. This also facilitates the
possibility to let the amount of information available within the data
of a subject for a parameter determine to which degree the group level
distribution dominates the estimation of the subject-specific
parameters. Hence, to approximate the conditional posterior distribution
of each subject, the covariance matrix is set to be a combination of the
covariance matrix obtained from the subject data and the group level
covariance matrix <span class="math inline">\(\Phi_{i}\)</span> or <span class="math inline">\(\Psi_i\)</span>. To estimate the covariance matrix
from the subject data, which is only used for the proposal distribution
of the RW Metropolis sampler, we simply use a Maximum Likelihood
Estimate (MLE), as this quantity is only used for the purpose of scaling
the proposal distribution and is not part of the estimated parameter
values that constitute the posterior distribution. The MLE estimate of
the covariance matrix is obtained by maximizing the likelihood of the
Multinomial Logit (MNL) model on the data, and retrieving the Hessian
matrix <span class="math inline">\(H_{ki}\)</span> (i.e., the second
order partial derivatives of the likelihood function with respect to the
parameters). The covariance matrix of the parameters is the inverse of
the Hessian matrix, <span class="math inline">\(H_{ki}^{-1}\)</span>.
Hence, the covariance matrices for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, are defined
by <span class="math inline">\(\Sigma_{\boldsymbol{\alpha}_{(O)ki}} =
(H_{\alpha(O) ki} + \Phi_{i}^{-1})^{-1}\)</span> and <span class="math inline">\(\Sigma_{\boldsymbol{\alpha}_{(S)ki}} =
(H_{\alpha(S) ki} + \Psi_i^{-1})^{-1}\)</span>, respectively. For <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span>, the data on
which the Hessian is obtained is the frequency with which a categorical
outcome is observed in state <span class="math inline">\(i\)</span> of
subject <span class="math inline">\(k\)</span>. For <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, this data is
the frequency with which state <span class="math inline">\(i\)</span>
transitions to another state within subject <span class="math inline">\(k\)</span>. Hence, the subject-specific covariance
matrix (i.e., the inverse of the Hessian matrix) is based on the sampled
hidden state sequence. Therefore, the MLE estimates of the
subject-specific covariance matrices that are used for the RW Metropolis
proposal distributions have to be obtained in each iteration, as the
sampled hidden state sequence changes in each iteration.<br />
A potential problem with maximizing the log-likelihood of each subject’s
data, is that a certain state might not be sampled for a subject. To
circumvent this problem, we modify the subject likelihood function by
adding a so-called regularizing likelihood function that has a defined
maximum to the subject-level likelihood function. We maximize the
resulting pooled likelihood function in order to obtain the MLE
estimates. Here, we use the likelihood function of the combined data
over all subjects that are considered to be part of one group as the
regularizing likelihood function. The pooled likelihood function is
scaled by <span class="math inline">\(1-w \times \text{subject-level
likelihood} + w \times \text{overall likelihood}^{n.obs_k /
N.obs}\)</span>, so that the overall likelihood function does not
dominate the subject-level likelihood function, and where <span class="math inline">\(n.obs_k\)</span> is the number of data
observations for subject <span class="math inline">\(k\)</span> and
<span class="math inline">\(N.obs\)</span> is the total number of data
observations over all subjects in a group.<br />
Now that we defined the covariance matrix <span class="math inline">\(\Sigma\)</span> for the scale of the RW Metropolis
sampler proposal distribution, we have to define the scalar factor <span class="math inline">\(s^2\)</span> to obtain the scale <span class="math inline">\(s^2\Sigma\)</span> of the proposal distribution.
As in <span class="citation">Rossi, Allenby, and McCulloch
(2012)</span>}, we adopt the scaling proposal of <span class="citation">Roberts, Rosenthal, et al. (2001)</span>, and set
scaling to <span class="math inline">\(s^2 = (2.93 /
\sqrt{\text{n.param}})^2\)</span>, where <span class="math inline">\(n.param\)</span> is the number of parameters to be
estimated for <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> or <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> in the RW
Metropolis sampler, which equals <span class="math inline">\(m -
1\)</span> in case of <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> (where <span class="math inline">\(m\)</span> denotes the number of states) and <span class="math inline">\(q - 1\)</span> in case of <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> (where <span class="math inline">\(q\)</span> denotes the number of categorical
outcomes).<br />
In summary, the scale parameter <span class="math inline">\(s^2\Sigma_{\alpha(O) ki}\)</span> and <span class="math inline">\(s^2\Sigma_{\alpha(S) ki}\)</span> of the proposal
distributions of the RW Metropolis sampler for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> are defined
as: <span class="math display">\[\begin{align}
s^2\Sigma_{\alpha(O) ki} = (2.93 / \sqrt{q-1})^2 &amp; \: \times \:
(H_{\alpha(O) ki} + \Phi_{i}^{-1})^{-1}, \ \text{and} \\
s^2\Sigma_{\alpha(S) ki} = (2.93 / \sqrt{m-1})^2 &amp; \: \times \:
(H_{\alpha(S) ki} + \Psi_i^{-1})^{-1} ,
\end{align}\]</span> where <span class="math inline">\(H_{\alpha(O)
ki}\)</span> is the Hessian of the <span class="math inline">\(k^{th}\)</span> subject’s data of the frequency
with which a categorical outcome is observed within state <span class="math inline">\(i\)</span> evaluated at the MLE of the pooled
likelihood, <span class="math inline">\(H_{\alpha(S) ki}\)</span> is the
Hessian of the <span class="math inline">\(k^{th}\)</span> subject’s
data of the frequency with which state <span class="math inline">\(i\)</span> transitions to another state evaluated
at the MLE of the pooled likelihood, and <span class="math inline">\(\Phi_{i}^{-1}\)</span> and <span class="math inline">\(\Psi_i^{-1}\)</span> are the inverses of the group
level covariance matrices. This provides us with <span class="math inline">\(m\)</span> pairs of scale parameters that closely
resemble the scale of the subject-level conditional posterior
distribution, and that 1) are automatically tuned (i.e., we do not
require experimentation to determine <span class="math inline">\(s^2\)</span> to tune the covariance matrix), 2)
allow the amount of information available within the data of a specific
subject to determine the degree to which the group level distribution
dominates the estimation of that subject’s level parameters, and 3) do
not require each state to be sampled in the hidden state sequence as not
each subject-level likelihood is required to have a maximum.</p>
</div>
<div id="full-conditional-posterior-distributions-of-the-multilevel-hmm" class="section level2">
<h2>Full conditional posterior distributions of the multilevel HMM</h2>
<p>In the hybrid Metropolis within Gibbs sampler, all level 2 model
parameters are directly sampled from their full conditional posterior
distributions. The full conditional posterior distributions are obtained
by applying Bayes theorem, combining the (hyper-)prior distribution of
the model parameter and the likelihood function. Direct sampling from
the conditional posterior distributions for these model parameters is
possible, as the choice of the (hyper-)prior distribution results in a
closed form expression of the full conditional posterior distribution.
That is:</p>
<ul>
<li>The full conditional posterior distributions of $_{i} $ and <span class="math inline">\(\Psi_i\)</span> (i.e., the state <span class="math inline">\(i\)</span> specific group covariance between the
subject <span class="math inline">\(k\)</span> batches of the <span class="math inline">\(q-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> pertaining to
the subject-specific state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span>, and the state
<span class="math inline">\(i\)</span> specific group covariance between
the subject <span class="math inline">\(k\)</span> batches of the <span class="math inline">\(m-1\)</span> random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> pertaining to
the subject-specific state transition probabilities, <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span>) are: <span class="math display">\[\begin{align}
\Pr(\Phi_{i} \mid \ ) \: &amp; \sim \text{IW}(\Phi_{ci}, df_c)\\
\Phi_{ci} \: &amp; = \Phi_{0} + (\boldsymbol{\alpha}_{(O)ki} -
\boldsymbol{X}\boldsymbol{\mu_{(O)ci}})^\top(\boldsymbol{\alpha}_{(O)ki}
- \boldsymbol{X}\boldsymbol{\mu_{(O)ci}}) \: + \nonumber \\
&amp; \quad \Big(\boldsymbol{\mu_{(O)ci}} - \begin{bmatrix}
\boldsymbol{\alpha}_{(O)0} \\ \boldsymbol{\beta}_{(O)0}
\end{bmatrix}\Big)^\top \boldsymbol{K_0} \Big(\boldsymbol{\mu_{(O)ci}} -
\begin{bmatrix} \boldsymbol{\alpha}_{(O)0} \\ \boldsymbol{\beta}_{(O)0}
\end{bmatrix} \Big)\nonumber \\
\boldsymbol{\mu_{(O)ci}} \: &amp; = (\boldsymbol{X}^\top \boldsymbol{X}
+ \boldsymbol{K_0})^{-1} \Big(X^\top \boldsymbol{\alpha}_{(O)ki} +
\boldsymbol{K_0} \begin{bmatrix} \boldsymbol{\alpha}_{(O)0} \\
\boldsymbol{\beta}_{(O)0} \end{bmatrix}\Big) \nonumber \\
df_c \: &amp; = df_0 + K \nonumber
\end{align}\]</span> <span class="math display">\[\begin{align}
\Pr(\Psi_i \mid \ ) \: &amp; \sim \text{IW}(\Psi_{ci}, df_c ) \\
\Psi_{ci} \: &amp; = \Psi_{0} + (\boldsymbol{\alpha}_{(S)ki} -
\boldsymbol{X}\boldsymbol{\mu_{(S)ci}})^\top(\boldsymbol{\alpha}_{(S)ki}
- \boldsymbol{X}\boldsymbol{\mu_{(S)ci}}) \: + \nonumber \\
&amp; \quad \Big(\boldsymbol{\mu_{(S)ci}} - \begin{bmatrix}
\boldsymbol{\alpha}_{(S)0} \\ \boldsymbol{\beta}_{(S)0}
\end{bmatrix}\Big)^\top \boldsymbol{K_0} \Big(\boldsymbol{\mu_{(S)ci}} -
\begin{bmatrix} \boldsymbol{\alpha}_{(S)0} \\ \boldsymbol{\beta}_{(S)0}
\end{bmatrix} \Big)\nonumber \\
\boldsymbol{\mu_{(S)ci}} \: &amp; = (\boldsymbol{X}^\top \boldsymbol{X}
+ \boldsymbol{K_0})^{-1} \Big(X^\top \boldsymbol{\alpha}_{(S)ki} +
\boldsymbol{K_0} \begin{bmatrix} \boldsymbol{\alpha}_{(S)0} \\
\boldsymbol{\beta}_{(S)0} \end{bmatrix}\Big) \nonumber \\
df_c \: &amp; = df_0 + K  \nonumber
\end{align}\]</span> where <span class="math inline">\(x^T\)</span> is
the transpose of <span class="math inline">\(x\)</span>, <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span> denote a
vector of chosen mean values of the Normal hyper-prior distribution on
the group mean vector <span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(S)i}\)</span>,
respectively, <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span> denote a vector
of chosen values of the Normal hyper-prior distribution on fixed
regression parameters <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>, respectively,
<span class="math inline">\(\boldsymbol{K_0}\)</span> denotes a diagonal
matrix with on the diagonal the number of observations (i.e., the number
of hypothetical prior subjects) on which the prior values <span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(O)i}\)</span>, <span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(S)0}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>, and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span> are based,
<span class="math inline">\(K\)</span> denotes the total number of
subjects in the dataset, <span class="math inline">\(\Phi_0\)</span> and
<span class="math inline">\(\Psi_0\)</span> denote the chosen prior
covariance values of the Inverse Wishart hyper-prior distribution on the
group covariance <span class="math inline">\(\Phi_i\)</span> and <span class="math inline">\(\Psi_i\)</span>, respectively, and <span class="math inline">\(df_0\)</span> denotes the prior specified degrees
of freedom of the Inverse Wishart hyper-prior distribution on the group
covariance <span class="math inline">\(\Phi_i\)</span> and <span class="math inline">\(\Psi_i\)</span>.</li>
<li>The full conditional posterior distributions of <span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span>, and
<span class="math inline">\(\boldsymbol{\bar{\alpha}}_{(S)i}\)</span>
and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>
(i.e., the state <span class="math inline">\(i\)</span> specific group
mean vector of the subject-specific batches of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> pertaining to
the state-dependent probabilities and state transition probabilities,
respectively, and the fixed regression coefficients predicting the
subject-specific batches of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>) are: <span class="math display">\[\begin{align}
\Pr\Big(\begin{bmatrix}  \boldsymbol{\bar{\alpha}}_{(O)i} \\ \
\boldsymbol{\beta}_{(O)i} \end{bmatrix} \mid\ \Big) \: &amp; \sim
\text{N}\Big( \boldsymbol{\mu_{(O)ci}}, \tfrac{1}{K_c} \Phi_{i}\Big)\\
\boldsymbol{\mu_{(O)ci}} \: &amp; = \Big(\boldsymbol{X}^\top
\boldsymbol{X} + \boldsymbol{K_0}\Big)^{-1} \Big(X^\top
\boldsymbol{\alpha}_{(O)ki} + \boldsymbol{K_0} \begin{bmatrix}
\boldsymbol{\alpha}_{(O)0} \\ \boldsymbol{\beta}_{(O)0}
\end{bmatrix}\Big) \nonumber \\
K_c \: &amp; = K + K_0 \nonumber
\end{align}\]</span> <span class="math display">\[\begin{align}
\Pr\Big(\begin{bmatrix}  \boldsymbol{\bar{\alpha}}_{(S)i}
\\  \boldsymbol{\beta}_{(S)i} \end{bmatrix} \mid \ \Big) \: &amp; \sim
\text{N}\Big(\boldsymbol{\mu_{(S)ci}}, \tfrac{1}{K_c} \Psi_i\Big)\\
\boldsymbol{\mu_{(S)ci}} \: &amp; = \Big(\boldsymbol{X}^\top
\boldsymbol{X} + \boldsymbol{K_0}\Big)^{-1} \Big(X^\top
\boldsymbol{\alpha}_{(S)ki} + \boldsymbol{K_0} \begin{bmatrix}
\boldsymbol{\alpha}_{(S)0} \\ \boldsymbol{\beta}_{(S)0}
\end{bmatrix}\Big) \nonumber \\
K_c \: &amp; = K + K_0 \nonumber
\end{align}\]</span> where <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span> denote the
chosen mean values of the Normal hyper-prior distribution on the group
mean vector <span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(O)i}\)</span> and
<span class="math inline">\(\bar{\boldsymbol{\alpha}}_{(S)i}\)</span>,
respectively, <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span> denote a vector
of chosen values of the Normal hyper-prior distribution on fixed
regression parameters <span class="math inline">\(\boldsymbol{\beta}_{(O)i}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{(S)i}\)</span>, <span class="math inline">\(K_0\)</span> denotes the number of observations
(i.e., the number of hypothetical prior subjects) on which the prior
values <span class="math inline">\(\boldsymbol{\alpha}_{(O)0}\)</span>,
<span class="math inline">\(\boldsymbol{\alpha}_{(S)0}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{(O)0}\)</span>, and <span class="math inline">\(\boldsymbol{\beta}_{(S)0}\)</span> are based, and
<span class="math inline">\(K\)</span> denotes the total number of
subjects in the dataset.</li>
</ul>
<p>For the random intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span>, related to
the subject-specific state-dependent probabilities of observing a
categorical outcome <span class="math inline">\(\boldsymbol{\theta}_{ki}\)</span> and the
subject-specific state transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_{k}\)</span>, respectively,
the choice of prior distributions does not result in closed form
expressions of the full conditional posterior distributions. That is,
for the subject-specific sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> related to
the subject-specific state-dependent probabilities of observing a
categorical outcome within state <span class="math inline">\(i\)</span>,
the full conditional posterior distribution when we assess a standard
multivariate normal prior is: <span class="math display">\[\begin{align}
  Pr(\boldsymbol{\alpha}_{(O)ki} \mid ) \: &amp; \propto
L\big(\boldsymbol{\alpha}_{(O)ki} \mid O_{kt}, S_{kt} = i\big)
\Pr\big(\boldsymbol{\alpha}_{(O)ki} \mid
\boldsymbol{\bar{\alpha}}_{(O)i}, \boldsymbol{\beta_{(O)i}},
\Phi_{i}\big),\\
  \Pr\big(\boldsymbol{\alpha}_{(O)ki} \mid
\boldsymbol{\bar{\alpha}}_{(O)i}, \boldsymbol{\beta_{(O)i}},
\Phi_{i}\big) \: &amp; \sim \text{N}( \boldsymbol{\bar{\alpha}}_{(O)i} +
\boldsymbol{X^\top} \boldsymbol{\beta_{(O)i}}, \Phi_{i}\big)), \nonumber
  \end{align}\]</span> and the likelihood is the product of the
probabilities of the observed outcomes <span class="math inline">\(O_{kt} = l \in \{1, 2, \ldots, q\}\)</span> within
sampled states <span class="math inline">\(S = i\)</span> in subject
<span class="math inline">\(k\)</span> over time points <span class="math inline">\(t\)</span>: <span class="math display">\[\begin{align}
  L\big(\boldsymbol{\alpha}_{(O)ki} \mid O_{kt}, S_{kt} = i\big) \:
&amp; = \prod_{{t}} Pr( O_{k,{t}} = l \mid S_{kt} = i,
\boldsymbol{\alpha}_{(O)ki}), \\
  Pr( O_{k,{t}} = l \mid S_{kt} = i, \boldsymbol{\alpha}_{(O)ki}) \:
&amp; = \frac{\text{exp}(\alpha_{(O)kil})}{1 + \sum_{\bar{l} = 2}^q
\text{exp}(\alpha_{(O)ki\bar{l}})}, \nonumber
  \end{align}\]</span> where the product is restricted to the set of
time points that coincide with the sampled state <span class="math inline">\(S\)</span> for subject <span class="math inline">\(k\)</span> at time point <span class="math inline">\(t\)</span> being <span class="math inline">\(i\)</span>, and <span class="math inline">\(q\)</span> is the number of categorical outcomes.
The numerator is set equal to one for <span class="math inline">\(l =
1\)</span>, making the first categorical outcome in the set the baseline
category in every state.<br />
For the subject-specific sets of intercepts <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> related to
the state-transition probabilities to transition from state <span class="math inline">\(i\)</span> to any of the other states <span class="math inline">\(j \in \{1, 2, \ldots,\)</span> <span class="math inline">\(m\}\)</span>, the full conditional posterior
distribution when we assess a standard multivariate normal prior is:
<span class="math display">\[\begin{align}
  Pr(\boldsymbol{\alpha}_{(S)ki} \mid ) \: &amp; \propto
L\big(\boldsymbol{\alpha}_{(S)ki} \mid S_{kt}, S_{k(t-1)} = i \big)
\Pr\big(\boldsymbol{\alpha}_{(S)ki} \mid
\boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{\beta_{(S)i}},
\Psi_i\big),\\
  \Pr\big(\boldsymbol{\alpha}_{(S)ki} \mid
\boldsymbol{\bar{\alpha}}_{(S)i}, \boldsymbol{\beta_{(S)i}},
\Psi_{i}\big) \: &amp; \sim \text{N}(\boldsymbol{\bar{\alpha}}_{(S)i} +
\boldsymbol{X^\top} \boldsymbol{\beta_{(S)i}}, \Psi_{i}), \nonumber
  \end{align}\]</span> and the likelihood is the product of the
probabilities of the observed transitions from state <span class="math inline">\(i\)</span> in the previous time point <span class="math inline">\(t-1\)</span> to any of the other states <span class="math inline">\(S_{kt} = j\)</span> over time points <span class="math inline">\(t\)</span> in subject <span class="math inline">\(k\)</span>:</p>
<p><span class="math display">\[\begin{align}
  L\big(\boldsymbol{\alpha}_{(S)ki} \mid S_{kt}, S_{k(t-1)} = i \big) \:
&amp; = \prod_{{n}} Pr( S_{k,{t}} = j \mid S_{k(t-1)} = i,
\boldsymbol{\alpha}_{(S)ki}), \\
  Pr( S_{k,{t}} = j \mid S_{k(t-1)} = i, \boldsymbol{\alpha}_{(S)ki}) \:
&amp; =  \frac{\text{exp}(\alpha_{(S)kij})}{1 + \sum_{\bar{j} \in Z}
\text{exp}(\alpha_{(S)k i\bar{j}})}, \nonumber
  \end{align}\]</span> <span class="math display">\[\begin{equation}
  \text{where} \ Z \in \{1, 2, \ldots, m, \ Z \neq 1 \} \nonumber
  \end{equation}\]</span> where the product is restricted to the set of
time points that coincide with the sampled state <span class="math inline">\(S\)</span> in the previous time point <span class="math inline">\(t-1\)</span> being <span class="math inline">\(i\)</span> for subject <span class="math inline">\(k\)</span>, and <span class="math inline">\(m\)</span> is the number of states. The numerator
is set equal to 1 for <span class="math inline">\(j = 1\)</span>, making
the first state of every row of the transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span> the baseline
category.<br />
As the conditional posterior distributions for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> do not result
in a closed form expression of a know distribution, we cannot directly
sample values of <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> from their
conditional posterior distributions with pre-defined equations on how to
obtain the current (i.e., updated using a combination of the value of
the hyper-prior and the data) parameters of the conditional posterior
distributions. Instead, new values for <span class="math inline">\(\boldsymbol{\alpha}_{(O)ki}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_{(S)ki}\)</span> are sampled
using a RW Metropolis sampler, as described above.<br /></p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-altman2007" class="csl-entry">
Altman, Rachel MacKay. 2007. <span>“Mixed Hidden <span>M</span>arkov
Models: An Extension of the Hidden <span>M</span>arkov Model to the
Longitudinal Data Setting.”</span> <em>Journal of the American
Statistical Association</em> 102 (477): 201–10.
</div>
<div id="ref-baum1970" class="csl-entry">
Baum, Leonard E, Ted Petrie, George Soules, and Norman Weiss. 1970.
<span>“A Maximization Technique Occurring in the Statistical Analysis of
Probabilistic Functions of <span>M</span>arkov Chains.”</span> <em>The
Annals of Mathematical Statistics</em>, 164–71.
</div>
<div id="ref-cappe2005" class="csl-entry">
Cappé, E. AND Rydén, O. AND Moulines. 2005. <em>Inference in Hidden
<span>M</span>arkov Models</em>. New York: Springer.
</div>
<div id="ref-dempster1977" class="csl-entry">
Dempster, Arthur P, Nan M Laird, and Donald B Rubin. 1977.
<span>“Maximum Likelihood from Incomplete Data via the EM
Algorithm.”</span> <em>Journal of the Royal Statistical Society. Series
B (Methodological)</em>, 1–38.
</div>
<div id="ref-gelman2014" class="csl-entry">
Gelman, Andrew, John B Carlin, Hal S Stern, and Donald B Rubin. 2014.
<em>Bayesian Data Analysis</em>. Vol. 2. London: Taylor &amp; Francis.
</div>
<div id="ref-Goldstein2011" class="csl-entry">
Goldstein, Harvey. 2011. <em>Multilevel Statistical Models</em>. 4th ed.
West Sussex: John Wiley &amp; Sons.
</div>
<div id="ref-Hox2017" class="csl-entry">
Hox, Joop J, Mirjam Moerbeek, and Rens van de Schoot. 2017.
<em>Multilevel Analysis: Techniques and Applications. 3rd Edn</em>. New
York, NY: Routledge.
</div>
<div id="ref-jasra2005" class="csl-entry">
Jasra, Ajay, CC Holmes, and DA Stephens. 2005. <span>“Markov Chain
<span>M</span>onte <span>C</span>arlo Methods and the Label Switching
Problem in <span>B</span>ayesian Mixture Modeling.”</span>
<em>Statistical Science</em>, 50–67.
</div>
<div id="ref-lynch2007" class="csl-entry">
Lynch, Scott M. 2007. <em>Introduction to Applied <span>B</span>ayesian
Statistics and Estimation for Social Scientists</em>. New York: Springer
Science &amp; Business Media.
</div>
<div id="ref-Rabiner1989" class="csl-entry">
Rabiner, Lawrence R. 1989. <span>“A Tutorial on Hidden
<span>M</span>arkov Models and Selected Applications in Speech
Recognition.”</span> <em>Proceedings of the IEEE</em> 77 (2): 257–86.
</div>
<div id="ref-roberts2001" class="csl-entry">
Roberts, Gareth O, Jeffrey S Rosenthal, et al. 2001. <span>“Optimal
Scaling for Various Metropolis-Hastings Algorithms.”</span>
<em>Statistical Science</em> 16 (4): 351–67.
</div>
<div id="ref-rossi2012" class="csl-entry">
Rossi, Peter E, Greg M Allenby, and Rob McCulloch. 2012. <em>Bayesian
Statistics and Marketing</em>. West Sussex: John Wiley &amp; Sons.
</div>
<div id="ref-ryden2008" class="csl-entry">
Rydén, Tobias. 2008. <span>“<span>EM</span> Versus <span>M</span>arkov
Chain <span>M</span>onte <span>C</span>arlo for Estimation of Hidden
<span>M</span>arkov Models: A Computational Perspective.”</span>
<em>Bayesian Analysis</em> 3 (4): 659–88.
</div>
<div id="ref-scott2002" class="csl-entry">
Scott, Steven L. 2002. <span>“Bayesian Methods for Hidden
<span>M</span>arkov Models.”</span> <em>Journal of the American
Statistical Association</em> 97 (457).
</div>
<div id="ref-Snijders2011" class="csl-entry">
Snijders, Tom, and Roel Bosker. 2011. <em>Multilevel Analysis: An
Introduction to Basic and Applied Multilevel Analysis</em>. London:
Sage.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
